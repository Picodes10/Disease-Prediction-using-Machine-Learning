{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parkinsons disease :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=pd.read_csv('parkinsson.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.head()\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='status',kind='count',data=a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in a:\n",
    "    if i != 'status' and i != 'name':\n",
    "        sns.catplot(x='status',y=i,kind='box',data=a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=a.drop(['name'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.metrics import accuracy_score,mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=a.drop(['status','name'],axis=1)\n",
    "labels=a['status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=MinMaxScaler((-1,1))\n",
    "x=scaler.fit_transform(features)\n",
    "y=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x, y, test_size=0.2, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross validation:\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBRFClassifier,XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier,BaggingClassifier,ExtraTreesClassifier,GradientBoostingClassifier,RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=cross_val_score(LogisticRegression(),x_train,y_train)\n",
    "xgbc=cross_val_score(XGBRFClassifier(),x_train,y_train)\n",
    "xgb=cross_val_score(XGBClassifier(),x_train,y_train)\n",
    "svm=cross_val_score(SVC(),x_train,y_train)\n",
    "#nb=cross_val_score(MultinomialNB(),x_train,y_train)\n",
    "dtc=cross_val_score(DecisionTreeClassifier(),x_train,y_train)\n",
    "adb=cross_val_score(AdaBoostClassifier(),x_train,y_train)\n",
    "bbc=cross_val_score(BaggingClassifier(),x_train,y_train)\n",
    "etc=cross_val_score(ExtraTreesClassifier(),x_train,y_train)\n",
    "gbc=cross_val_score(GradientBoostingClassifier(),x_train,y_train)\n",
    "rfc=cross_val_score(RandomForestClassifier(),x_train,y_train)\n",
    "#vc=cross_val_score(VotingClassifier(estimators),x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('log reg',lr,lr.mean())\n",
    "print('xgbd',xgbc,xgbc.mean())\n",
    "print('xgb',xgb,xgb.mean())\n",
    "print('svm',svm,svm.mean())\n",
    "#print('nb',nb,nb.mean)\n",
    "print('dtc',dtc,dtc.mean())\n",
    "print('adb',adb,adb.mean())\n",
    "print('bbc',bbc,bbc.mean())\n",
    "print('etc',etc,etc.mean())\n",
    "print('gbc',gbc,gbc.mean())\n",
    "print('rfc',rfc,rfc.mean())\n",
    "#print('vc',vc,vc.mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGboost:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First a model is fit using the xgboost algorithm(no parameter tuning is done)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=XGBClassifier()\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predtr=model.predict(x_train)\n",
    "print(accuracy_score(y_train,y_predtr)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    y_pred=model.predict(x_test)\n",
    "    print(accuracy_score(y_test, y_pred)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra trees classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ExtraTreesClassifier()\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " y_pred=model.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predtr=model.predict(x_train)\n",
    "print(accuracy_score(y_train,y_predtr)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=pd.DataFrame(y_pred)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of algorithms and their accuracy scores\n",
    "algorithms = {\n",
    "    \"Logistic Regression\": lr.mean(),\n",
    "    \"XGBRFClassifier\": xgbc.mean(),\n",
    "    \"XGBClassifier\": xgb.mean(),\n",
    "    \"SVC\": svm.mean(),\n",
    "    \"Decision Tree Classifier\": dtc.mean(),\n",
    "    \"AdaBoost Classifier\": adb.mean(),\n",
    "    \"Bagging Classifier\": bbc.mean(),\n",
    "    \"Extra Trees Classifier\": etc.mean(),\n",
    "    \"Gradient Boosting Classifier\": gbc.mean(),\n",
    "    \"Random Forest Classifier\": rfc.mean()\n",
    "}\n",
    "\n",
    "# Print each algorithm with its accuracy score\n",
    "for algorithm, accuracy in algorithms.items():\n",
    "    print(f\"{algorithm}: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model import\n",
    "\n",
    "import pickle\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(x_train, y_train)  # Replace with your data\n",
    "\n",
    "with open('model1.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)\n",
    "\n",
    "with open('model1.pkl', 'rb') as file:\n",
    "    loaded_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "model = joblib.load('model1.pkl')\n",
    "print(type(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# ✅ Load the trained model\n",
    "model = joblib.load('model1.pkl')\n",
    "\n",
    "# ✅ Check if the model is fitted\n",
    "if hasattr(model, \"predict\"):\n",
    "    print(\"✅ Model is loaded and ready to predict!\")\n",
    "else:\n",
    "    print(\"❌ Model is not fitted yet.\")\n",
    "\n",
    "# Test the loaded model\n",
    "print(loaded_model.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import pickle\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"parkinsson.csv\")  # Replace with actual file\n",
    "\n",
    "# Select only the required 10 features\n",
    "selected_features = ['mdvp_fo', 'mdvp_fhi', 'mdvp_flo', 'mdvp_jitter', 'mdvp_shimmer',\n",
    "                     'hnr', 'rpde', 'dfa', 'spread1', 'spread2']\n",
    "X = df[selected_features]\n",
    "y = df['target']  # Ensure the target variable is correct\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train ExtraTreesClassifier\n",
    "model = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save the new model\n",
    "with open(\"model1.pkl\", \"wb\") as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load the trained model\n",
    "with open('model1.pkl', 'rb') as file:\n",
    "    model = pickle.load(file)\n",
    "\n",
    "# Example input (use real test values)\n",
    "sample_input = np.array([119.992, 157.302, 74.997, 0.00784, 0.044, 21.033, 0.414, 0.815, -4.813, 0.266]).reshape(1, -1)\n",
    "\n",
    "# Predict\n",
    "try:\n",
    "    result = model.predict(sample_input)[0]\n",
    "    print(\"Test Prediction:\", 'Parkinson’s Detected' if result == 1 else 'No Parkinson’s')\n",
    "except Exception as e:\n",
    "    print(\"Model Error:\", str(e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
