{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"liver-disease.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXPLORATORY DATA ANALYSIS :-**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes[df.dtypes=='object']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of Numberical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(figsize=(15,15), xrot=-45,bins=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertdataset(x):\n",
    "    if x==2:\n",
    "        return 0\n",
    "    return 1\n",
    "df['Dataset'] = df['Dataset'].map(convertdataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Dataset.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include=['object'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bar plots for categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.countplot(y='Gender', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Gender'] == 'Male'][['Dataset','Gender']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"Age\", y=\"Gender\", hue=\"Dataset\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical Value Handling\n",
    "def convertgender(x):\n",
    "    if x== 'Male':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "df['Gender'] = df['Gender'].map(convertgender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positive Correlation-> one feature increases other also increases\n",
    "Negative Correlation-> one feature increases other decreases\n",
    "closer to 0-> weak relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(df.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "mask = np.zeros_like(df.corr())\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "plt.figure(figsize=(10,10))\n",
    "with sns.axes_style(\"white\"):\n",
    "    ax = sns.heatmap(df.corr()*100, mask=mask, fmt = \".0f\", annot=True, lw=1, cmap=ListedColormap(['green','yellow','red','blue']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing Outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df.Aspartate_Aminotransferase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df.Total_Bilirubin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Aspartate_Aminotransferase.sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.Aspartate_Aminotransferase<=3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Aspartate_Aminotransferase.sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.Aspartate_Aminotransferase<=2500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df.Dataset\n",
    "X=df.drop('Dataset', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical columns\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"Gender\"] = label_encoder.fit_transform(df[\"Gender\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train , y_test = train_test_split(X,y, test_size=0.2, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Ridge Classifier\": RidgeClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"SVM (Linear)\": SVC(kernel='linear'),\n",
    "    \"SVM (RBF Kernel)\": SVC(kernel='rbf')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Accuracy: 0.7699\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.34      0.46        32\n",
      "           1       0.78      0.94      0.85        81\n",
      "\n",
      "    accuracy                           0.77       113\n",
      "   macro avg       0.74      0.64      0.66       113\n",
      "weighted avg       0.76      0.77      0.74       113\n",
      "\n",
      "\n",
      "Ridge Classifier Accuracy: 0.7257\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.06      0.11        32\n",
      "           1       0.73      0.99      0.84        81\n",
      "\n",
      "    accuracy                           0.73       113\n",
      "   macro avg       0.70      0.53      0.48       113\n",
      "weighted avg       0.71      0.73      0.63       113\n",
      "\n",
      "\n",
      "Decision Tree Accuracy: 0.5929\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.50      0.41        32\n",
      "           1       0.76      0.63      0.69        81\n",
      "\n",
      "    accuracy                           0.59       113\n",
      "   macro avg       0.55      0.56      0.55       113\n",
      "weighted avg       0.64      0.59      0.61       113\n",
      "\n",
      "\n",
      "Random Forest Accuracy: 0.6814\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.38      0.40        32\n",
      "           1       0.76      0.80      0.78        81\n",
      "\n",
      "    accuracy                           0.68       113\n",
      "   macro avg       0.60      0.59      0.59       113\n",
      "weighted avg       0.67      0.68      0.67       113\n",
      "\n",
      "\n",
      "Gradient Boosting Accuracy: 0.6903\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.44      0.44        32\n",
      "           1       0.78      0.79      0.79        81\n",
      "\n",
      "    accuracy                           0.69       113\n",
      "   macro avg       0.62      0.61      0.61       113\n",
      "weighted avg       0.69      0.69      0.69       113\n",
      "\n",
      "\n",
      "XGBoost Accuracy: 0.6814\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.50      0.47        32\n",
      "           1       0.79      0.75      0.77        81\n",
      "\n",
      "    accuracy                           0.68       113\n",
      "   macro avg       0.62      0.63      0.62       113\n",
      "weighted avg       0.69      0.68      0.69       113\n",
      "\n",
      "\n",
      "K-Nearest Neighbors Accuracy: 0.6637\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.50      0.46        32\n",
      "           1       0.79      0.73      0.76        81\n",
      "\n",
      "    accuracy                           0.66       113\n",
      "   macro avg       0.60      0.61      0.61       113\n",
      "weighted avg       0.68      0.66      0.67       113\n",
      "\n",
      "\n",
      "SVM (Linear) Accuracy: 0.7168\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        32\n",
      "           1       0.72      1.00      0.84        81\n",
      "\n",
      "    accuracy                           0.72       113\n",
      "   macro avg       0.36      0.50      0.42       113\n",
      "weighted avg       0.51      0.72      0.60       113\n",
      "\n",
      "\n",
      "SVM (RBF Kernel) Accuracy: 0.7168\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        32\n",
      "           1       0.72      1.00      0.84        81\n",
      "\n",
      "    accuracy                           0.72       113\n",
      "   macro avg       0.36      0.50      0.42       113\n",
      "weighted avg       0.51      0.72      0.60       113\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:25:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Train & Evaluate Models\n",
    "model_results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    model_results[name] = accuracy\n",
    "    print(f\"\\n{name} Accuracy: {accuracy:.4f}\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning for Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "best_rf = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tuned Random Forest Accuracy: 0.6991150442477876\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.41      0.43        32\n",
      "           1       0.78      0.81      0.80        81\n",
      "\n",
      "    accuracy                           0.70       113\n",
      "   macro avg       0.62      0.61      0.61       113\n",
      "weighted avg       0.69      0.70      0.69       113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Tuned Random Forest\n",
    "y_pred_rf = best_rf.predict(X_test_scaled)\n",
    "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "model_results[\"Tuned Random Forest\"] = rf_accuracy\n",
    "print(\"\\nTuned Random Forest Accuracy:\", rf_accuracy)\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Comparison Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  Accuracy\n",
      "0  Logistic Regression  0.769912\n",
      "1     Ridge Classifier  0.725664\n",
      "7         SVM (Linear)  0.716814\n",
      "8     SVM (RBF Kernel)  0.716814\n",
      "9  Tuned Random Forest  0.699115\n",
      "4    Gradient Boosting  0.690265\n",
      "3        Random Forest  0.681416\n",
      "5              XGBoost  0.681416\n",
      "6  K-Nearest Neighbors  0.663717\n",
      "2        Decision Tree  0.592920\n"
     ]
    }
   ],
   "source": [
    "# Convert model results into a DataFrame\n",
    "model_comparison_df = pd.DataFrame(model_results.items(), columns=[\"Model\", \"Accuracy\"])\n",
    "\n",
    "# Sort models by accuracy in descending order\n",
    "model_comparison_df = model_comparison_df.sort_values(by=\"Accuracy\", ascending=False)\n",
    "\n",
    "print(model_comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7606837606837606\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.92      0.85        87\n",
      "           2       0.56      0.30      0.39        30\n",
      "\n",
      "    accuracy                           0.76       117\n",
      "   macro avg       0.68      0.61      0.62       117\n",
      "weighted avg       0.73      0.76      0.73       117\n",
      "\n",
      "Model and Scaler Saved Successfully!\n",
      " Model and Scaler savedðŸ‘Œ\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pickle\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('liver-disease.csv')\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoders = {}\n",
    "categorical_columns = ['Gender']\n",
    "\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "X = df.drop(columns=['Dataset']) \n",
    "y = df['Dataset']\n",
    "\n",
    "# Handle missing values by filling with the mean of each column\n",
    "X = X.fillna(X.mean())\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train Logistic Regression Model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Save Model & Scaler\n",
    "with open('model3.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)\n",
    "\n",
    "with open('scaler.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler, file)\n",
    "\n",
    "print(\"Model and Scaler Saved Successfully!\")\n",
    "\n",
    "\n",
    "# Save the model\n",
    "with open('model3.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)\n",
    "with open('model3.pkl', 'rb') as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "\n",
    "# If you used StandardScaler, save it as well\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "with open('scaler.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler, file)\n",
    "with open('scaler.pkl', 'rb') as file:\n",
    "    loaded_scaler = pickle.load(file)\n",
    "    \n",
    "    \n",
    "print(\" Model and Scaler savedðŸ‘Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "model = joblib.load('model3.pkl')\n",
    "print(type(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1\n",
      " 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2\n",
      " 1 1 2 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1\n",
      " 1 1 1 1 2 2]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Test the loaded model\n",
    "print(loaded_model.predict(X_test_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loaded: LogisticRegression()\n",
      "Scaler Loaded: StandardScaler()\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load model\n",
    "with open('model3.pkl', 'rb') as file:\n",
    "    model = pickle.load(file)\n",
    "\n",
    "# Load scaler (if used)\n",
    "try:\n",
    "    with open('scaler.pkl', 'rb') as file:\n",
    "        scaler = pickle.load(file)\n",
    "except FileNotFoundError:\n",
    "    scaler = None  # If no scaler, we'll proceed without it\n",
    "\n",
    "print(\"Model Loaded:\", model)\n",
    "print(\"Scaler Loaded:\", scaler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Case 1: Prediction = Liver Disease\n",
      "Test Case 2: Prediction = No Liver Disease\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "test_inputs = [\n",
    "    [45, 1, 1.2, 0.5, 220, 50, 30, 6.8, 3.4, 1.1],  # Example 1\n",
    "    [25, 0, 0.8, 0.3, 180, 40, 25, 7.2, 4.0, 1.3],  # Example 2\n",
    "]\n",
    "\n",
    "for i, test in enumerate(test_inputs):\n",
    "    test_array = np.array(test).reshape(1, -1)\n",
    "    \n",
    "    if scaler:\n",
    "        test_array = scaler.transform(test_array)\n",
    "    \n",
    "    pred = model.predict(test_array)[0]\n",
    "    print(f\"Test Case {i+1}: Prediction = {'Liver Disease' if pred == 1 else 'No Liver Disease'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
