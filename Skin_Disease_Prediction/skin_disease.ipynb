{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77c2866a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset path\n",
    "DATASET_DIR = \"dataset\"\n",
    "IMAGE_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 5  # You can increase later if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e3b86a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccf25d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Removed 0 broken images.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def remove_broken_images(folder_path):\n",
    "    removed = 0\n",
    "    for subdir, _, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(subdir, file)\n",
    "            try:\n",
    "                img = Image.open(file_path)\n",
    "                img.verify()  # This will raise an exception for corrupt images\n",
    "            except Exception as e:\n",
    "                if os.path.exists(file_path):  # Check if the file exists\n",
    "                    print(f\"Removing broken image: {file_path}\")\n",
    "                    os.remove(file_path)\n",
    "                else:\n",
    "                    print(f\"File not found, skipping: {file_path}\")\n",
    "                removed += 1\n",
    "    print(f\"✅ Removed {removed} broken images.\")\n",
    "\n",
    "remove_broken_images(\"dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3326b573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 557 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "# ── Create the training generator ────────────────────────────────────────────\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    DATASET_DIR,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    subset='training'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c560530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved class_indices mapping: {'Actinic keratosis': 0, 'Atopic Dermatitis': 1, 'Benign keratosis': 2, 'Dermatofibroma': 3, 'Melanocytic nevus': 4, 'Melanoma': 5, 'Squamous cell carcinoma': 6, 'Tinea Ringworm Candidiasis': 7, 'Vascular lesion': 8}\n"
     ]
    }
   ],
   "source": [
    "# ── SAVE the mapping from class name → index ─────────────────────────────────\n",
    "os.makedirs(\"models\", exist_ok=True)               # ensure folder exists\n",
    "with open(\"models/skin_class_indices.json\", \"w\") as f:\n",
    "    json.dump(train_generator.class_indices, f)\n",
    "print(\"Saved class_indices mapping:\", train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "560a7e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 139 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "# Validation generator\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    DATASET_DIR,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7f7448b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 791ms/step - accuracy: 0.2309 - loss: 2.1750 - val_accuracy: 0.4964 - val_loss: 1.4989\n",
      "Epoch 2/5\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 672ms/step - accuracy: 0.5756 - loss: 1.2587 - val_accuracy: 0.6259 - val_loss: 1.1496\n",
      "Epoch 3/5\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 653ms/step - accuracy: 0.6929 - loss: 0.9848 - val_accuracy: 0.6547 - val_loss: 0.9754\n",
      "Epoch 4/5\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 621ms/step - accuracy: 0.7501 - loss: 0.7803 - val_accuracy: 0.6763 - val_loss: 0.9172\n",
      "Epoch 5/5\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 619ms/step - accuracy: 0.7630 - loss: 0.7322 - val_accuracy: 0.6691 - val_loss: 0.8837\n",
      "✅ Model saved at models/skin_model.h5\n"
     ]
    }
   ],
   "source": [
    "# Base model\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "predictions = Dense(len(train_generator.class_indices), activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train!\n",
    "model.fit(train_generator, validation_data=val_generator, epochs=EPOCHS)\n",
    "\n",
    "# Save model\n",
    "model.save(\"models/skin_model.keras\")\n",
    "print(\"✅ Model saved at models/skin_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
